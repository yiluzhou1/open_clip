{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 429/1217 [05:54<13:22,  1.02s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (91393600 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 35%|███▌      | 430/1217 [05:56<16:24,  1.25s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (94633984 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (95160025 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (94090000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 434/1217 [06:07<30:29,  2.34s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (95707089 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 436/1217 [06:11<31:18,  2.40s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (92467456 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 36%|███▌      | 440/1217 [06:22<33:20,  2.58s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (93026025 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 47%|████▋     | 576/1217 [09:30<23:42,  2.22s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (90345025 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 56%|█████▋    | 685/1217 [12:08<15:24,  1.74s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (91929744 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 59%|█████▊    | 713/1217 [12:59<14:29,  1.73s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (90878089 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 59%|█████▉    | 718/1217 [13:08<14:43,  1.77s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (93547584 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 63%|██████▎   | 766/1217 [14:30<18:26,  2.45s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (91107025 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 63%|██████▎   | 772/1217 [14:44<16:44,  2.26s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (93257649 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 66%|██████▌   | 803/1217 [15:29<15:01,  2.18s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (96805921 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 66%|██████▌   | 806/1217 [15:35<14:03,  2.05s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (89794576 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 69%|██████▊   | 836/1217 [16:18<09:18,  1.47s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (90022144 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 837/1217 [16:20<09:55,  1.57s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (89718784 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 839/1217 [16:24<10:40,  1.69s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (90136036 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 69%|██████▉   | 841/1217 [16:29<13:26,  2.15s/it]/opt/miniconda/envs/yz_openclip1/lib/python3.11/site-packages/PIL/Image.py:3074: DecompressionBombWarning: Image size (91374481 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1217/1217 [39:46<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3942, 0.3942, 0.3942]) tensor([0.2378, 0.2378, 0.2378])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate the mean and standard deviation of the dataset\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Resize, ToTensor, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = '/mnt/eds_share/share/Spine2D/GlobusSrgMapData_crop_square/train/'\n",
    "# dataset_path = '/mnt/eds_share/share/Body_Parts_XRay/Original/train/'\n",
    "# Define the transform\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),  # Resize all images to 512x512\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "# Create the dataset with the transform\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Create the DataLoader with the transformed dataset\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# Compute the mean and standard deviation\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _ in tqdm(dataloader):\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "\n",
    "mean /= len(dataloader.dataset)\n",
    "std /= len(dataloader.dataset)\n",
    "\n",
    "print(mean, std) #tensor([0.4233, 0.4233, 0.4233]) tensor([0.2114, 0.2114, 0.2114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3942, 0.3942, 0.3942]) tensor([0.2378, 0.2378, 0.2378])\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1390/1390 [00:05<00:00, 277.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 89.24861701751402, Standard Deviation: 65.85327891219714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_dataset_stats(image_folder):\n",
    "    all_means = []\n",
    "    all_stds = []\n",
    "\n",
    "    # Iterate over all images in the folder\n",
    "    for fname in tqdm(os.listdir(image_folder)):\n",
    "        image_path = os.path.join(image_folder, fname)\n",
    "        \n",
    "        # Open image and convert to grayscale\n",
    "        img = Image.open(image_path).convert('RGB') #.convert('L')\n",
    "        img_np = np.array(img)\n",
    "        \n",
    "        # Compute mean and standard deviation for the image\n",
    "        img_mean = img_np.mean()\n",
    "        img_std = img_np.std()\n",
    "        \n",
    "        all_means.append(img_mean)\n",
    "        all_stds.append(img_std)\n",
    "    \n",
    "    # Compute overall mean and standard deviation for the dataset\n",
    "    overall_mean = np.mean(all_means)\n",
    "    overall_std = np.mean(all_stds)\n",
    "\n",
    "    return overall_mean, overall_std\n",
    "\n",
    "# image_folder = '/mnt/eds_share/share/Spine2D/GlobusSrgMapData_crop_square/train/'\n",
    "image_folder = '/mnt/eds_share/share/Body_Parts_XRay/Original/train/images'\n",
    "mean, std = compute_dataset_stats(image_folder)\n",
    "print(f\"Mean: {mean}, Standard Deviation: {std}\") \n",
    "# Mean: 89.24861701751402, Standard Deviation: 65.85327891219714 for Body_Parts_XRay\n",
    "# 0.3942, 0.3942, 0.3942 for Spine2D-Mean\n",
    "# 0.2378, 0.2378, 0.2378 for Spine2D-Std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mlfoundations/open_clip/issues/439\n",
    "\n",
    "#Code to implement data augmentation: --aug-cfg scale='(0.33, 1.0)' re_prob=0.35\n",
    "\"\"\"\n",
    "A.Affine(rotate=(-15, 15), translate_percent=(0.0, 0.25), shear=(-3, 3), p=0.5),\n",
    "A.RandomResizedCrop(image_size[0], image_size[1], scale=(0.9, 1.0), ratio=(0.75, 1.3333333333)),\n",
    "A.ToGray(p=0.1),\n",
    "A.GaussianBlur(blur_limit=(3, 7), p=0.05),\n",
    "A.GaussNoise(p=0.05),\n",
    "A.RandomGridShuffle(grid=(2, 2), p=0.3),\n",
    "A.Posterize(p=0.2),\n",
    "A.RandomBrightnessContrast(p=0.5),\n",
    "A.Cutout(p=0.05),\n",
    "A.RandomSnow(p=0.1),\n",
    "A.RandomRain(p=0.05),\n",
    "A.HorizontalFlip(p=0.5),\n",
    "\"\"\"\n",
    "\n",
    "from torchvision.transforms import Normalize, Compose, RandomResizedCrop, InterpolationMode, ToTensor, Resize, CenterCrop\n",
    "\n",
    "def _convert_to_rgb(image):\n",
    "    return image.convert('RGB')\n",
    "normalize = Normalize(mean=mean, std=std)\n",
    "train_transform = Compose([\n",
    "    RandomResizedCrop(\n",
    "        image_size,\n",
    "        scale=aug_cfg_dict.pop('scale'),\n",
    "        interpolation=InterpolationMode.BICUBIC,\n",
    "    ),\n",
    "    _convert_to_rgb,\n",
    "    ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import (Normalize, Compose, RandomResizedCrop, RandomRotation, \n",
    "                                   RandomHorizontalFlip, ColorJitter, RandomAffine, \n",
    "                                   GaussianBlur, RandomCrop, RandomErasing, InterpolationMode, \n",
    "                                   ToTensor, Resize, CenterCrop, Lambda)\n",
    "import random, torch\n",
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = F.to_tensor(img).numpy() * 255  # Convert to numpy array in range [0, 255]\n",
    "        img = img.transpose(1, 2, 0)  # Convert from CxHxW to HxWxC\n",
    "        img = self.transform(image=img)['image']\n",
    "        img = F.to_pil_image(img.astype('uint8'))  # Convert back to PIL image\n",
    "        return img\n",
    "\n",
    "\n",
    "class AlbumentationsTransform2:\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)  # Convert to numpy array\n",
    "        img = self.transform(image=img)['image']\n",
    "        return Image.fromarray(img)  # Convert back to PIL image\n",
    "\n",
    "\n",
    "class RandomAugmentation:\n",
    "    def __init__(self, probability, *transforms):\n",
    "        self.probability = probability\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() <= self.probability:\n",
    "            for transform in self.transforms:\n",
    "                img = transform(img)\n",
    "        return img\n",
    "\n",
    "def invert_background(img):\n",
    "    # Convert the background color for xray images\n",
    "    img = ImageOps.invert(img)\n",
    "    return img\n",
    "\n",
    "# Define the CLAHE transformation\n",
    "clahe = A.CLAHE(p=1.0, clip_limit=6.0, tile_grid_size=(12, 12))\n",
    "\n",
    "# Define the mean and standard deviation of the dataset\n",
    "MEAN = (0.3942, 0.3942, 0.3942)#(0.48145466, 0.4578275, 0.40821073)\n",
    "STD = (0.2378, 0.2378, 0.2378)#(0.26862954, 0.26130258, 0.27577711)\n",
    "image_size = (224,224)\n",
    "\n",
    "def _convert_to_rgb(image):\n",
    "    return image.convert('RGB')\n",
    "\n",
    "# Albumentations transformations\n",
    "albu_transforms = A.Compose([\n",
    "    # A.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),  # Elastic deformation\n",
    "    # A.HistogramMatching(p=0.5, reference_images=None),  # Histogram Equalization (note: you need reference images)\n",
    "    # Add any other albumentations transforms here\n",
    "    A.GaussianBlur(p=0.3, blur_limit=(3, 5))\n",
    "])\n",
    "\n",
    "# torchvision transforms\n",
    "pre_rotation = Compose([\n",
    "    RandomRotation(degrees=15),\n",
    "])\n",
    "\n",
    "pre_resize = Compose([\n",
    "    RandomResizedCrop(\n",
    "        image_size,\n",
    "        scale=(0.9, 1.1),\n",
    "        interpolation=InterpolationMode.BICUBIC,\n",
    "    ),\n",
    "])\n",
    "\n",
    "pre_transforms = Compose([\n",
    "    RandomHorizontalFlip(p=0.5),\n",
    "    ColorJitter(brightness=0.15, contrast=0.15),\n",
    "    RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    RandomCrop(size=image_size, padding=10),\n",
    "])\n",
    "\n",
    "post_transforms = Compose([\n",
    "    _convert_to_rgb,\n",
    "    ToTensor(),\n",
    "    # RandomErasing(p=0.2, scale=(0.01, 0.05), ratio=(0.3, 3.3), value=0, inplace=False),  # Cutout or Random Erasing\n",
    "])\n",
    "\n",
    "train_transform = Compose([\n",
    "    AlbumentationsTransform2(clahe),\n",
    "    RandomAugmentation(0.2, Lambda(invert_background)),\n",
    "    # RandomAugmentation(0.3, pre_rotation),\n",
    "    pre_resize,\n",
    "    # 0.3 means 30% of images will be augmented\n",
    "    # RandomAugmentation(0.3, pre_transforms, AlbumentationsTransform(albu_transforms)),\n",
    "    post_transforms\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To visualize the augmentation on a few images, you can follow the steps below:\n",
    "\n",
    "Load a few images.\n",
    "Apply the transformation pipeline train_transform to each image.\n",
    "Display the original and augmented images side by side using matplotlib.\n",
    "\n",
    "Remember to change path_to_your_images to the directory where your images are located. \n",
    "The code will display the original and augmented images side by side for the first five images in the directory. \n",
    "This will allow you to inspect the effects of your augmentation pipeline.\n",
    "\"\"\"\n",
    "import os, random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_pil = ToPILImage()\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/eds_ml/Users/Yilu_ML/open_clip/tests/')\n",
    "from image_augmentation import customized_augmentation\n",
    "\n",
    "image_size = (224,224)\n",
    "train_transform = customized_augmentation(image_size)\n",
    "\n",
    "\n",
    "def visualize_augmentations(original_img, augmented_img):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(original_img, cmap=\"gray\") #\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(augmented_img, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Enhanced Image\")\n",
    "    for a in ax:\n",
    "        a.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# def visualize_augmentations(original_img, augmented_img, histogram_original, histogram_augmented):\n",
    "#     fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "    \n",
    "#     ax[0, 0].imshow(original_img, cmap=\"gray\")\n",
    "#     ax[0, 0].set_title(\"Original Image\")\n",
    "    \n",
    "#     ax[0, 1].imshow(augmented_img, cmap=\"gray\")\n",
    "#     ax[0, 1].set_title(\"Augmented Image\")\n",
    "    \n",
    "#     ax[1, 0].hist(histogram_original, bins=256, range=(0,256), density=True, color='gray', alpha=0.7)\n",
    "#     ax[1, 0].set_xlabel('Pixel Intensity')\n",
    "#     ax[1, 0].set_ylabel('Frequency')\n",
    "#     ax[1, 0].set_title('Histogram of Original Image')\n",
    "    \n",
    "#     ax[1, 1].hist(histogram_augmented, bins=256, range=(0,256), density=True, color='gray', alpha=0.7)\n",
    "#     ax[1, 1].set_xlabel('Pixel Intensity')\n",
    "#     ax[1, 1].set_ylabel('Frequency')\n",
    "#     ax[1, 1].set_title('Histogram of Augmented Image')\n",
    "\n",
    "       \n",
    "#     for a in ax.ravel():\n",
    "#         a.axis(\"off\")\n",
    "#     # Enable axis for histogram\n",
    "#     ax[1, 0].axis(\"on\")\n",
    "#     ax[1, 1].axis(\"on\")   \n",
    "    \n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# Load a few images\n",
    "# image_folder = '/mnt/eds_share/share/Body_Parts_XRay/images/train/'\n",
    "image_folder = '/mnt/eds_share/share/Spine2D/GlobusSrgMapData_crop_square/train/images/'\n",
    "sample_images = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder)]\n",
    "# Set the random seed\n",
    "random.seed(42)\n",
    "sample_images = random.sample(sample_images, 10)\n",
    "\n",
    "for image_path in sample_images:\n",
    "    original_img = Image.open(image_path)\n",
    "    # print(np.array(original_img).max()/255., np.array(original_img).min()/255.)\n",
    "    augmented_img = train_transform(original_img)\n",
    "    # print(np.array(augmented_img).max(), np.array(augmented_img).min())\n",
    "    augmented_img = augmented_img.permute(1, 2, 0)  # Convert CxHxW to HxWxC for visualization\n",
    "    # print(augmented_img.shape)\n",
    "    \n",
    "    #histogram for original image\n",
    "    image = original_img.convert('L')\n",
    "    # Convert the image to a numpy array\n",
    "    histogram_original = np.array(image).ravel()\n",
    "    \n",
    "    #histogram for augmented image\n",
    "    augmented_img_permuted = augmented_img.permute(2, 0, 1)\n",
    "    augmented_img_pil = to_pil(augmented_img_permuted)\n",
    "    augmented_img_gray = augmented_img_pil.convert('L')\n",
    "    # Convert the image to a numpy array\n",
    "    histogram_augmented = np.array(augmented_img_gray).ravel()\n",
    "    \n",
    "    # visualize_augmentations(original_img, augmented_img, histogram_original, histogram_augmented)\n",
    "    visualize_augmentations(original_img, augmented_img)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yz_openclip1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
